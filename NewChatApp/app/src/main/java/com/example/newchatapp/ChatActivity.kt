package com.example.newchatapp

import android.Manifest
import android.content.Context
import android.content.Intent
import android.content.pm.PackageManager
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaRecorder
import android.os.Bundle
import android.speech.SpeechRecognizer
import android.util.Log
import android.view.LayoutInflater
import android.view.View
import android.view.ViewGroup
import android.widget.Button
import android.widget.EditText
import android.widget.ImageButton
import android.widget.TextView
import androidx.activity.enableEdgeToEdge
import androidx.activity.result.contract.ActivityResultContracts
import androidx.appcompat.app.AppCompatActivity
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import androidx.core.view.ViewCompat
import androidx.core.view.WindowInsetsCompat
import androidx.lifecycle.lifecycleScope
import androidx.recyclerview.widget.LinearLayoutManager
import androidx.recyclerview.widget.RecyclerView
import com.google.api.gax.core.FixedCredentialsProvider
import com.google.api.gax.rpc.ApiStreamObserver
import com.google.auth.oauth2.GoogleCredentials
import com.google.cloud.speech.v1.RecognitionConfig
import com.google.cloud.speech.v1.SpeechClient
import com.google.cloud.speech.v1.SpeechSettings
import com.google.cloud.speech.v1.StreamingRecognitionConfig
import com.google.cloud.speech.v1.StreamingRecognizeRequest
import com.google.cloud.speech.v1.StreamingRecognizeResponse
import com.google.protobuf.ByteString
import kotlinx.coroutines.CoroutineScope
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import okhttp3.MediaType.Companion.toMediaTypeOrNull
import okhttp3.OkHttpClient
import okhttp3.Request
import okhttp3.RequestBody.Companion.toRequestBody
import org.json.JSONObject

// -------------------------
// ë°ì´í„° í´ë˜ìŠ¤ & ì—´ê±°í˜•
// -------------------------
data class ChatMessage(
    var message: String,         // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì‹¤ì‹œê°„ ê°±ì‹ ì„ ìœ„í•´ var
    val type: MessageType
)

enum class MessageType {
    SENT,
    RECEIVED
}

// -------------------------
// RecyclerView ì–´ëŒ‘í„°
// -------------------------
class ChatAdapter(private val messages: List<ChatMessage>) :
    RecyclerView.Adapter<RecyclerView.ViewHolder>() {

    companion object {
        private const val VIEW_TYPE_SENT = 1
        private const val VIEW_TYPE_RECEIVED = 2
    }

    override fun getItemViewType(position: Int): Int {
        return when (messages[position].type) {
            MessageType.SENT -> VIEW_TYPE_SENT
            MessageType.RECEIVED -> VIEW_TYPE_RECEIVED
        }
    }

    override fun onCreateViewHolder(parent: ViewGroup, viewType: Int): RecyclerView.ViewHolder {
        return if (viewType == VIEW_TYPE_SENT) {
            val view = LayoutInflater.from(parent.context)
                .inflate(R.layout.sent_message_bubble, parent, false)
            SentMessageViewHolder(view)
        } else {
            val view = LayoutInflater.from(parent.context)
                .inflate(R.layout.received_message_bubble, parent, false)
            ReceivedMessageViewHolder(view)
        }
    }

    override fun getItemCount(): Int = messages.size

    override fun onBindViewHolder(holder: RecyclerView.ViewHolder, position: Int) {
        val chatMessage = messages[position]
        when (holder) {
            is SentMessageViewHolder -> holder.bind(chatMessage)
            is ReceivedMessageViewHolder -> holder.bind(chatMessage)
        }
    }

    // ë‚´ê°€ ë³´ë‚¸ ë©”ì‹œì§€ (ì˜¤ë¥¸ìª½ ë§í’ì„ )
    class SentMessageViewHolder(itemView: View) : RecyclerView.ViewHolder(itemView) {
        private val sentMessageText: TextView = itemView.findViewById(R.id.sent_message_bubble)
        fun bind(chatMessage: ChatMessage) {
            sentMessageText.text = chatMessage.message
        }
    }

    // GPT/ìƒëŒ€ë°© ë©”ì‹œì§€ (ì™¼ìª½ ë§í’ì„ )
    class ReceivedMessageViewHolder(itemView: View) : RecyclerView.ViewHolder(itemView) {
        private val receivedMessageText: TextView =
            itemView.findViewById(R.id.receive_message_bubble)
        fun bind(chatMessage: ChatMessage) {
            receivedMessageText.text = chatMessage.message
        }
    }
}

// -------------------------
// ì•¡í‹°ë¹„í‹°
// -------------------------
class ChatActivity : AppCompatActivity() {

    private lateinit var transcriptEditText: EditText
    private lateinit var startButton: Button
    private lateinit var stopButton: Button
    private lateinit var confirmButton: Button

    private var recording = false
    private var audioRecord: AudioRecord? = null
    private var speechClient: SpeechClient? = null
    private var speechRecognizer: SpeechRecognizer? = null

    private val sampleRate = 48000
    private var packetCount = 0
    private var lastTranscript: String = "" // âœ… ë§ˆì§€ë§‰ ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì €ì¥ ë³€ìˆ˜
    private val bufferSize = AudioRecord.getMinBufferSize(
        sampleRate,
        AudioFormat.CHANNEL_IN_MONO,
        AudioFormat.ENCODING_PCM_16BIT
    )

    private lateinit var chatRecyclerView: RecyclerView
    private lateinit var messageEditText: EditText
    private lateinit var sendButton: ImageButton

    // ì±„íŒ… ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    private val chatMessages = mutableListOf<ChatMessage>()

    // RecyclerView ì–´ëŒ‘í„°
    private lateinit var chatAdapter: ChatAdapter
    private var currentResponseMessage: ChatMessage? = null
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        enableEdgeToEdge()          // ì—£ì§€ íˆ¬ ì—£ì§€ ëª¨ë“œ
        setContentView(R.layout.activity_chat)

        // ì‹œìŠ¤í…œ ë°”(ìƒë‹¨Â·í•˜ë‹¨) íŒ¨ë”© ì ìš©
        ViewCompat.setOnApplyWindowInsetsListener(findViewById(R.id.main)) { v, insets ->
            val systemBars = insets.getInsets(WindowInsetsCompat.Type.systemBars())
            v.setPadding(systemBars.left, systemBars.top, systemBars.right, systemBars.bottom)
            insets
        }

        // ë·° ì°¸ì¡°
        chatRecyclerView = findViewById(R.id.chat_recyclerView)
        messageEditText = findViewById(R.id.message_edit)
        sendButton = findViewById(R.id.send_btn)

        // RecyclerView ì„¤ì •
        chatAdapter = ChatAdapter(chatMessages)
        chatRecyclerView.adapter = chatAdapter
        chatRecyclerView.layoutManager = LinearLayoutManager(this)

        // ë©”ì‹œì§€ ì „ì†¡ ë²„íŠ¼ í´ë¦­ ë¦¬ìŠ¤ë„ˆ
        sendButton.setOnClickListener {
            // 1. ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë©”ì‹œì§€ë¥¼ sentMessage ë³€ìˆ˜ì— ì €ì¥
            val sentMessage: String = messageEditText.text.toString().trim()
            if (sentMessage.isNotEmpty()) {
                // 2. ë³´ë‚¸ ë©”ì‹œì§€ ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ RecyclerViewì— ì¶”ê°€ (sent_message_bubble.xml ì‚¬ìš©)
                val newSentMessage = ChatMessage(sentMessage, MessageType.SENT)
                chatMessages.add(newSentMessage)
                chatAdapter.notifyItemInserted(chatMessages.size - 1)
                chatRecyclerView.scrollToPosition(chatMessages.size - 1) // ë§ˆì§€ë§‰ ë©”ì‹œì§€ ë³´ì´ë„ë¡ ìŠ¤í¬ë¡¤
                messageEditText.text.clear()
                // **3. ìƒˆë¡œìš´ ë°›ì€ ë©”ì‹œì§€ UI ìš”ì†Œ ìƒì„± (ì´ˆê¸° ìƒíƒœ - ë¹„ì–´ ìˆê±°ë‚˜ ë¡œë”© í‘œì‹œ)**
                currentResponseMessage = ChatMessage("", MessageType.RECEIVED) // ë¹ˆ ë©”ì‹œì§€ ê°ì²´ ìƒì„±
                currentResponseMessage?.let {
                    chatMessages.add(it)
                    chatAdapter.notifyItemInserted(chatMessages.size - 1)
                    chatRecyclerView.scrollToPosition(chatMessages.size - 1)
                }


                // 3. ì„œë²„ì— ì±„íŒ… ìš”ì²­ (sendChatRequest í•¨ìˆ˜ ì‚¬ìš©)
                lifecycleScope.launch { // lifecycleScope ì‚¬ìš©
                    sendChatRequest(sentMessage) { chunk:String -> // ì²­í¬ ë‹¨ìœ„ ì‘ë‹µ ì²˜ë¦¬
                        // 4. ë°›ì€ ì²­í¬ ë°ì´í„°ë¥¼ UIì— í‘œì‹œ (received_message_bubble.xml ì‚¬ìš©)
                        currentResponseMessage?.let { message ->
                            val updatedMessage = message.message + chunk // ê¸°ì¡´ ë©”ì‹œì§€ì— ì²­í¬ ì¶”ê°€
                            currentResponseMessage = message.copy(message = updatedMessage)

                            // UI ì—…ë°ì´íŠ¸ (í•´ë‹¹ ì•„ì´í…œë§Œ ì—…ë°ì´íŠ¸)
                            val messageIndex = chatMessages.indexOf(message)
                            if (messageIndex != -1) {
                                chatMessages[messageIndex] = currentResponseMessage!!
                                chatAdapter.notifyItemChanged(messageIndex)
                                chatRecyclerView.scrollToPosition(messageIndex)
                            }
                        }
                    }}}
        }
        speechRecognizer = SpeechRecognizer.createSpeechRecognizer(this)

        transcriptEditText = findViewById(R.id.message_edit)
        startButton = findViewById(R.id.start_button)
        stopButton = findViewById(R.id.stop_button)
        confirmButton = findViewById(R.id.confirm_button)

        requestAudioPermission()
        initializeGoogleCredentials()
        checkPermissions()

        stopButton.isEnabled = false

        SpeechRecognitionHelper.onStartRecognition = {
            startSpeechToText()
        }

        SpeechRecognitionHelper.onStopRecognition = {
            stopSpeechToText()
        }

        startButton.setOnClickListener {
            if (!recording) {
                val startIntent = Intent(this, STTService::class.java).apply {
                    putExtra("ACTION", "START")
                }
                startService(startIntent)

                startButton.isEnabled = false
                stopButton.isEnabled = true
            }
        }

        stopButton.setOnClickListener {
            pauseSpeechToText()

            val stopIntent = Intent(this, STTService::class.java).apply {
                putExtra("ACTION", "STOP")
            }
            startService(stopIntent)
        }

        confirmButton.setOnClickListener {
            val finalText = processFinalText(transcriptEditText.text.toString())
            transcriptEditText.setText(finalText)
            transcriptEditText.setSelection(transcriptEditText.text.length)

            finalizeSpeechRecognition()

            val confirmIntent = Intent(this, STTService::class.java).apply {
                putExtra("ACTION", "CONFIRM")
            }
            startService(confirmIntent)
        }
    }
    private fun finalizeSpeechRecognition() {
        val intent = Intent(this, STTService::class.java).apply {
            putExtra("ACTION", "CONFIRM")
        }
        startService(intent)
    }

    private fun checkPermissions() {
        if (ContextCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO)
            != PackageManager.PERMISSION_GRANTED) {
            ActivityCompat.requestPermissions(this, arrayOf(Manifest.permission.RECORD_AUDIO), 1001)
        }
    }

    private fun requestAudioPermission() {
        if (ContextCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO)
            != PackageManager.PERMISSION_GRANTED) {
            requestPermissionLauncher.launch(Manifest.permission.RECORD_AUDIO)
        }
    }

    private val requestPermissionLauncher = registerForActivityResult(
        ActivityResultContracts.RequestPermission()
    ) { isGranted: Boolean ->
        if (isGranted) {
            Log.d("STT", "Microphone permission granted")
        } else {
            Log.e("STT_ERROR", "Microphone permission denied")
        }
    }

    private fun initializeGoogleCredentials() {
        try {
            applicationContext.assets.open("service-account-key.json").use { inputStream ->
                val credentials = GoogleCredentials.fromStream(inputStream)
                    .createScoped(listOf("https://www.googleapis.com/auth/cloud-platform"))

                val speechSettings = SpeechSettings.newBuilder()
                    .setCredentialsProvider(FixedCredentialsProvider.create(credentials))
                    .build()

                speechClient = SpeechClient.create(speechSettings)
                Log.d("STT", "âœ… Google Cloud Credentials loaded successfully!")
            }
        } catch (e: Exception) {
            Log.e("STT_ERROR", "âŒ Failed to set up credentials", e)
            speechClient = null
        }

        if (speechClient == null) {
            Log.e("STT_ERROR", "âŒ SpeechClient ì´ˆê¸°í™” ì‹¤íŒ¨ - credentials ì„¤ì • ì˜¤ë¥˜ ê°€ëŠ¥ì„± ìˆìŒ")
        } else {
            Log.d("STT", "âœ… SpeechClientê°€ ì •ìƒì ìœ¼ë¡œ ì´ˆê¸°í™”ë¨")
        }
    }

    private fun startSpeechToText() {
        if (!isMicrophoneAvailable()) {
            Log.e("STT_ERROR", "ë§ˆì´í¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ")
            return
        }

        if (speechClient == null) {
            Log.e("STT_ERROR", "âŒ SpeechClientê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            return
        }

        try {
            audioRecord = AudioRecord(
                MediaRecorder.AudioSource.MIC,
                sampleRate,
                AudioFormat.CHANNEL_IN_MONO,
                AudioFormat.ENCODING_PCM_16BIT,
                bufferSize
            )

            if (audioRecord?.state != AudioRecord.STATE_INITIALIZED) {
                Log.e("STT_ERROR", "âŒ AudioRecord ì´ˆê¸°í™” ì‹¤íŒ¨")
                return
            }

            audioRecord?.startRecording()
            recording = true

            runOnUiThread {
                startButton.isEnabled = false
                stopButton.isEnabled = true
            }

            Log.d("STT", "ğŸ¤ ìŒì„± ì¸ì‹ ì‹œì‘ë¨")

            CoroutineScope(Dispatchers.IO).launch {
                try {
                    val responseObserver = object : ApiStreamObserver<StreamingRecognizeResponse> {
                        override fun onNext(response: StreamingRecognizeResponse?) {
                            Log.d("STT_DEBUG", "ğŸ¤ onNext() í˜¸ì¶œë¨")
                            response?.resultsList?.forEach { result ->
                                val transcript = result.alternativesList.joinToString { it.transcript }
                                Log.d("STT", "âœ… ì¸ì‹ëœ í…ìŠ¤íŠ¸(ì›ë³¸): $transcript")

                                runOnUiThread {
                                    val processedText = processFinalText(transcript)  // âœ… í…ìŠ¤íŠ¸ ì •ë¦¬ ì ìš©
                                    if (processedText != lastTranscript) {
                                        lastTranscript = processedText
                                        transcriptEditText.append(" $processedText")
                                        transcriptEditText.setSelection(transcriptEditText.text.length)
                                    } else {
                                        Log.d("STT", "ğŸ”„ ë™ì¼í•œ í…ìŠ¤íŠ¸ ê°ì§€ë¨, ì¶”ê°€ ì•ˆ í•¨")
                                    }
                                }
                            }
                        }

                        override fun onError(t: Throwable?) {
                            Log.e("STT_ERROR", "âŒ STT ì˜¤ë¥˜ ë°œìƒ: ${t?.message}")
                        }

                        override fun onCompleted() {
                            Log.d("STT", "âœ… STT ì™„ë£Œ")
                        }
                    }

                    val requestObserver = speechClient!!
                        .streamingRecognizeCallable()
                        .bidiStreamingCall(responseObserver)

                    val streamingConfig = StreamingRecognitionConfig.newBuilder()
                        .setConfig(
                            RecognitionConfig.newBuilder()
                                .setEncoding(RecognitionConfig.AudioEncoding.LINEAR16)
                                .setSampleRateHertz(sampleRate)
                                .setLanguageCode("ko-KR")
                                .setModel("default")
                                .build()
                        )
                        .setInterimResults(false)
                        .build()

                    requestObserver.onNext(
                        StreamingRecognizeRequest.newBuilder()
                            .setStreamingConfig(streamingConfig)
                            .build()
                    )

                    val buffer = ByteArray(bufferSize)
                    while (recording) {
                        val bytesRead = audioRecord?.read(buffer, 0, buffer.size) ?: 0

                        if (bytesRead > 0) {
                            packetCount++
                            if (packetCount % 10 == 0) {  // 10ë²ˆì§¸ íŒ¨í‚·ë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥
                                Log.d("STT", "ğŸ“¢ ìŒì„± ë°ì´í„° ì „ì†¡ ì¤‘: $bytesRead bytes")
                            }
                        } else {
                            Log.e("STT_ERROR", "âŒ ìŒì„± ë°ì´í„° ì—†ìŒ (bytesRead = $bytesRead)")
                        }

                        requestObserver.onNext(
                            StreamingRecognizeRequest.newBuilder()
                                .setAudioContent(ByteString.copyFrom(buffer, 0, bytesRead))
                                .build()
                        )
                    }
                    requestObserver.onCompleted()
                } catch (e: Exception) {
                    Log.e("STT_ERROR", "âŒ ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", e)
                }
            }
        } catch (e: Exception) {
            Log.e("STT_ERROR", "âŒ STT ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", e)
        }
    }

    private fun isMicrophoneAvailable(): Boolean {
        val audioManager = getSystemService(Context.AUDIO_SERVICE) as android.media.AudioManager
        return packageManager.hasSystemFeature(PackageManager.FEATURE_MICROPHONE) &&
                audioManager.mode != android.media.AudioManager.MODE_INVALID
    }

    private fun stopSpeechToText() {
        recording = false
        audioRecord?.stop()
        audioRecord?.release()
        audioRecord = null

        runOnUiThread {
            startButton.isEnabled = true
            stopButton.isEnabled = false
        }

        speechClient?.shutdown()  // ìµœì¢… ì¢…ë£Œ
        speechClient = null
        Log.d("STT", "ğŸ›‘ ìŒì„± ì¸ì‹ ì™„ì „ ì¢…ë£Œë¨")
    }

    private fun pauseSpeechToText() {
        if (recording) {
            recording = false  // ë…¹ìŒ ì¤‘ë‹¨
            audioRecord?.stop()  // ì˜¤ë””ì˜¤ ì…ë ¥ì„ ì¼ì‹œ ì •ì§€
            runOnUiThread {
                startButton.isEnabled = true  // ì‹œì‘ ë²„íŠ¼ í™œì„±í™”
                stopButton.isEnabled = false  // ì¤‘ì§€ ë²„íŠ¼ ë¹„í™œì„±í™”
            }
            Log.d("STT", "â¸ ìŒì„± ì¸ì‹ ì¼ì‹œ ì •ì§€ë¨")
        }
    }

    fun processFinalText(input: String): String {
        val cleaned = cleanUpText(input)  // ë¶ˆí•„ìš”í•œ ë°˜ë³µ ë¬¸ì ì œê±°
        return finalizeSentence(cleaned)  // ë¬¸ì¥ ëì— ì ì ˆí•œ êµ¬ë‘ì  ì¶”ê°€
    }

    private fun cleanUpText(input: String): String {
        val cleanedText = input.replace(Regex("(.)\\1{2,}"), "$1")  // ì¤‘ë³µ ë¬¸ì ì œê±°
        return cleanedText.replace(Regex("\\s+"), " ").trim()  // ê³µë°± ì •ë¦¬
    }

    private fun finalizeSentence(input: String): String {
        val trimmedText = input.trim()

        // ë¬¸ì¥ì´ ë¹„ì–´ìˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if (trimmedText.isEmpty()) return trimmedText

        // âœ… ì§ˆë¬¸ì´ë©´ ë¬¼ìŒí‘œ ì¶”ê°€
        if (trimmedText.endsWith("ë­ì•¼") || trimmedText.endsWith("ì–´ë–»ê²Œ") || trimmedText.endsWith("ì™œ") ||
            trimmedText.endsWith("ì¸ì§€") || trimmedText.endsWith("ì¸ê°€") || trimmedText.endsWith("ê¹Œ")) {
            return if (trimmedText.endsWith("?")) trimmedText else "$trimmedText?"
        }

        // âœ… ê¸°ì¡´ ì½”ë“œì—ì„œ ë§ˆì¹¨í‘œ ì¶”ê°€í•˜ëŠ” ë¶€ë¶„ì„ ì‚­ì œ (ì¤‘ìš”!)
        return trimmedText  // ë§ˆì¹¨í‘œ ì¶”ê°€ ì—†ì´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    }
}

    /**
     * ì„œë²„(GPT)ë¡œë¶€í„° ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ë°›ì•„ì˜¤ëŠ” í•¨ìˆ˜
     * - ì™¼ìª½ ë§í’ì„ ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸
     */


suspend fun sendChatRequest(userMessage: String, onChunk: (String) -> Unit) {
    withContext(Dispatchers.IO) {
        val client = OkHttpClient()
        val json = JSONObject().apply {
            put("message", userMessage)
        }
        val mediaType = "application/json; charset=utf-8".toMediaTypeOrNull()
        val requestBody = json.toString().toRequestBody(mediaType)
        val request = Request.Builder()
            .url("http://10.0.2.2:8000/stream-chat") // URL í™•ì¸ í•„ìš”
            .post(requestBody)
            .build()

        try {
            client.newCall(request).execute().use { response ->
                if (!response.isSuccessful) {
                    withContext(Dispatchers.Main) {
                        onChunk("Error: ${response.code}")
                    }
                    return@withContext
                }
                val source = response.body?.source() ?: run {
                    withContext(Dispatchers.Main) {
                        onChunk("Error: Response body is null")
                    }
                    return@withContext
                }
                val fixedBufferSize = 1024L

                while (true) {
                    if (!source.request(1L)) break

                    val available = source.buffer.size
                    if (available > 0) {
                        val bytesToRead = if (available >= fixedBufferSize) fixedBufferSize else available
                        val chunk = try {
                            source.readUtf8(bytesToRead)
                        } catch (readEx: Exception) {
                            withContext(Dispatchers.Main) {
                                onChunk("Stream Read Error: ${readEx.message}")
                            }
                            break
                        }
                        withContext(Dispatchers.Main) {
                            onChunk(chunk)
                        }
                    }
                }
            }
        } catch (e: Exception) {
            withContext(Dispatchers.Main) {
                onChunk("Stream Error: ${e.message}")
            }
        }
    }
}