from ai_app.common import client, model, makeup_response
import json
import requests
from pprint import pprint
from tavily import TavilyClient
import os
from ai_app.utils.writingRequirementsManager import WritingRequirementsManager


tavily = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))
global_lat_lon = { 
           'ì„œìš¸':[37.57,126.98],'ê°•ì›ë„':[37.86,128.31],'ê²½ê¸°ë„':[37.44,127.55],
           'ê²½ìƒë‚¨ë„':[35.44,128.24],'ê²½ìƒë¶ë„':[36.63,128.96],'ê´‘ì£¼':[35.16,126.85],
           'ëŒ€êµ¬':[35.87,128.60],'ëŒ€ì „':[36.35,127.38],'ë¶€ì‚°':[35.18,129.08],
           'ì„¸ì¢…ì‹œ':[36.48,127.29],'ìš¸ì‚°':[35.54,129.31],'ì „ë¼ë‚¨ë„':[34.90,126.96],
           'ì „ë¼ë¶ë„':[35.69,127.24],'ì œì£¼ë„':[33.43,126.58],'ì¶©ì²­ë‚¨ë„':[36.62,126.85],
           'ì¶©ì²­ë¶ë„':[36.79,127.66],'ì¸ì²œ':[37.46,126.71],
           'Boston':[42.36, -71.05],
           'ë„ì¿„':[35.68, 139.69]
          }
global_currency_code = {'ë‹¬ëŸ¬':'USD','ì—”í™”':'JPY','ìœ ë¡œí™”':'EUR','ìœ„ì•ˆí™”':'CNY','íŒŒìš´ë“œ':'GBP'}

def get_celsius_temperature(**kwargs):
    location = kwargs['location']
    lat_lon = global_lat_lon.get(location, None)
    if lat_lon is None:
        return None
    lat = lat_lon[0]
    lon = lat_lon[1]

    # API endpoint
    url = f"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current_weather=true"

    # APIë¥¼ í˜¸ì¶œí•˜ì—¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    response = requests.get(url)
    # ì‘ë‹µì„ JSON í˜•íƒœë¡œ ë³€í™˜
    data = response.json()
    # í˜„ì¬ ì˜¨ë„ ê°€ì ¸ì˜¤ê¸° (ì„­ì”¨)
    temperature = data['current_weather']['temperature']

    print("temperature:",temperature) 
    return temperature

def get_currency(**kwargs):    

    currency_name = kwargs['currency_name']
    currency_name = currency_name.replace("í™˜ìœ¨", "")
    currency_code = global_currency_code.get(currency_name, 'USD')
    
    if currency_code is None:
        return None

    response = requests.get(f"https://api.exchangerate-api.com/v4/latest/{currency_code}")
    data = response.json()
    krw = data['rates']['KRW']

    print("í™˜ìœ¨:", krw) 
    return krw

def search_internet(user_input: str,chat_context=None) -> str:
    
    try:
        print(f"ğŸ“¨ ì›¹ ê²€ìƒ‰ ìš”ì²­ ì‹œì‘: '{user_input}'")

        # âœ… ì‚¬ìš©ì ì…ë ¥ì„ input_text ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
       
        if chat_context:
            print("ğŸ”„ ë¬¸ë§¥ ì²˜ë¦¬ ì‹œì‘")
        # ìµœê·¼ Nê°œì˜ ë©”ì‹œì§€ë§Œ í¬í•¨ (ë„ˆë¬´ ë§ì€ ë¬¸ë§¥ì€ í† í°ì„ ë‚­ë¹„í•  ìˆ˜ ìˆìŒ)
            recent_messages = chat_context[-3:]  # ìµœê·¼ 3ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš©
            print(f"ğŸ“‹ ìµœê·¼ ë©”ì‹œì§€ ìˆ˜: {len(recent_messages)}")
            # ë¬¸ë§¥ ì •ë³´ë¥¼ ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
            for i, msg in enumerate(recent_messages):
                    print(f"ğŸ“ ë©”ì‹œì§€ {i + 1} ì—­í• : {msg.get('role', 'unknown')}")
                    content_preview = str(msg.get('content', ''))[:50] + "..." if len(str(msg.get('content', ''))) > 50 else str(msg.get('content', ''))
                    print(f"ğŸ“„ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {content_preview}")

            context_info = "\n".join([
                f"{msg.get('role', 'unknown')}: {msg.get('content', '')}" 
                for msg in recent_messages if msg.get('role') != 'system'
            ])
            
            
            search_text = client.responses.create(
                model="gpt-4o",
                input=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "input_text",
                            "text": f"{user_input}\n\n[ëŒ€í™” ë¬¸ë§¥]: {context_info} ì„ ì œê³µëœ ë¬¸ë§¥ì— ë§ê²Œ ê²€ìƒ‰ì–´ë¥¼ ìƒˆë¡œ ë§Œë“¤ì–´ë¼ <ì˜ˆ)/>  ë¬¸ë§¥: ì°½ì—…ê°€ì–‘ì„±êµìœ¡...; ì‚¬ìš©ì ìš”ì²­:25ë…„ ì •ë³´ë¡œ ê²€ìƒ‰í•´ì¤˜; ê²€ìƒ‰ì–´[ì°½ì—…ì–‘ì„±êµìœ¡ 25ë…„]ê²€ìƒ‰ì–´ëŠ” ë‹¨ì–´ì˜ ì¡°í•©ì´ì–´ì•¼ëœë‹¤.</ì˜ˆì˜ˆ>"
                        }
                    ]
                }
            ],
        ).output_text
            #print("ë¬¸ë§¥DEBUG!!!!!!!!!!!!!!!!!!")
            #print(search_text)
            #print("\n\n\n\n")
        else:
            search_text = user_input 
            #print("ì—†ëŠ” ë¬¸ë§¥DEBUG!!!!!!!!!!!!!!!!!!")
            #print(search_text)
            #print("\n\n\n\n")
        context_input = [
        {
            "role": "user",
            "content": [{"type": "input_text", "text": search_text}]
        }
    ]

        response = client.responses.create(
            model="gpt-4o",
            input=context_input,  
            text={"format": {"type": "text"}},
            reasoning={},
            tools=[{
                "type": "web_search_preview",
                "user_location": {
                    "type": "approximate",
                    "country": "KR"
                },
                "search_context_size": "medium"
            }],
            tool_choice={"type": "web_search_preview"},
            temperature=1,
            max_output_tokens=2048,
            top_p=1,
            store=True
        )
        
        # âœ… ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ ì—¬ë¶€ ë¡œê·¸
        if any(getattr(item, "type", None) == "web_search_call" for item in getattr(response, "output", [])):
            print("âœ… ğŸ” ì›¹ ê²€ìƒ‰ì´ ì‹¤ì œë¡œ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("âš ï¸ ì›¹ ê²€ìƒ‰ì´ ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # âœ… ì‘ë‹µ ë©”ì‹œì§€ ì¶”ì¶œ
        print("DEBUG: Extracting message object from response.output")

        # 1. message ê°ì²´ ì¶”ì¶œ (ResponseOutputMessage)
        message = next(
            (item for item in response.output if getattr(item, "type", None) == "message"),
            None
        )
        if not message:
            print("DEBUG: No message found")
            return "âŒ GPT ì‘ë‹µ ë©”ì‹œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # 2. content ì¤‘ output_text ë¸”ë¡ ì¶”ì¶œ
        print("DEBUG: Looking for output_text block in message.content")
        content_block = next(
            (block for block in message.content if getattr(block, "type", None) == "output_text"),
            None
        )
        if not content_block:
            print("DEBUG: output_text block not found")
            return "âŒ GPT ì‘ë‹µ ë‚´ output_text í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # 3. í…ìŠ¤íŠ¸ ì¶”ì¶œ
        output_text = getattr(content_block, "text", "").strip()
        print(f"DEBUG: Extracted output_text: {output_text}")

        # 4. ì¶œì²˜(annotation) íŒŒì‹±
        annotations = getattr(content_block, "annotations", [])
        print(f"DEBUG: Annotations: {annotations}")
        citations = []
        for a in annotations:
            if getattr(a, "type", None) == "url_citation":
                print(f"DEBUG: Found url_citation: {a}")
            title = getattr(a, "title", "ì¶œì²˜")
            url = getattr(a, "url", "")
            citations.append(f"[{title}]({url})")

        # 5. í…ìŠ¤íŠ¸ + ì¶œì²˜ ì¡°í•©
        result = output_text
        print(f"DEBUG: Collected citations: {citations}")
        if citations:
            result += "\n\nğŸ“ ì¶œì²˜:\n" + "\n".join(citations)
        
        return result+"ì´ ì‘ë‹µ í˜•ì‹ ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ì„¸ìš” ëŒ€ë‹µê³¼ ì¶œì²˜ê°€ í˜•ì‹ ê·¸ëŒ€ë¡œ ë‹¤ìŒëŒ€ë‹µì— ë‹´ê²¨ì•¼í•©ë‹ˆë‹¤.ì—„ë°€í•˜ê²Œ."

    

    except Exception as e:
        return f"ğŸš¨ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


    except Exception as e:
        return f"ğŸš¨ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


def search_internet_for_report(**kwargs):
    #print("search_internet",kwargs)
    response =tavily.search(query=kwargs['search_query'], max_results=2, search_depth="advanced")
    contents=[{"content":result['content'],"url":result['url']}
              for result in response['results']]
    #print("contents",contents)
    return f"ìˆ˜ì§‘ëœ ìë£Œ:{contents}"
report_system_role = """
ë‹¤ìŒ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œë¥¼ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ë³´ê³ ì„œ ì‘ì„± í›„ ë§ˆì§€ë§‰ì— ê²€ìƒ‰ì— í™œìš©í•œ urlì„ ê°ì£¼ë¡œ ë°˜ë“œì‹œ í‘œì‹œí•˜ì„¸ìš”.
"""
def write_report(**kwargs):   
    print('write_report',kwargs)
    response = client.chat.completions.create(
                    timeout=90,
                    model="gpt-4-1106-preview",  
                    messages=[
                        {"role": "system", "content": report_system_role},
                        {"role": "user", "content": kwargs['materials']}
                    ],
                )
    report = response.model_dump()['choices'][0]['message']['content']
    return report
tools = [
        {
            "type": "function",
            "name": "get_celsius_temperature",
            "description": "ì§€ì •ëœ ìœ„ì¹˜ì˜ í˜„ì¬ ì„­ì”¨ ë‚ ì”¨ í™•ì¸",
            "strict": True,
            "parameters": {
                "type": "object",
                "required": [
                    "location"
                ],
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "ê´‘ì—­ì‹œë„, e.g. ì„œìš¸, ê²½ê¸°"
                    }
                },
                "additionalProperties": False
            }
},
       {
           "type": "function",
            "name": "get_currency",
            "description": "ì§€ì •ëœ í†µí™”ì˜ ì›(KRW) ê¸°ì¤€ì˜ í™˜ìœ¨ í™•ì¸.",
            "strict": True,
            "parameters": {
                "type": "object",
                "required": [
                    "currency_name"
                ],
                "properties": {
                    "currency_name": {
                        "type": "string",
                        "description": "í†µí™”ëª…, e.g. ë‹¬ëŸ¬í™˜ìœ¨, ì—”í™”í™˜ìœ¨"
                    }
                },
                "additionalProperties": False
            }
            },
            {
            "type": "function",
            "name": "search_internet",
            "description": "Searches the internet based on user input and retrieves relevant information.",
            "strict": True,
            "parameters": {
                "type": "object",
                "required": [
                "user_input"
                ],
                "properties": {
                "user_input": {
                    "type": "string",
                    "description": "User's search query input(conversation context will be automatically added)"
                }
                },
                "additionalProperties": False
            }
            },
        {
  "type": "function",
  "name": "update_field",
  "description": """
ì‹œìŠ¤í…œì´ ì‚¬ìš©ìê°€ ì‘ì„± ìš”êµ¬ì‚¬í•­ ë‚´ì˜ íŠ¹ì • í•„ë“œë¥¼ ì—…ë°ì´íŠ¸í•˜ë ¤ëŠ” ì˜ë„ë¥¼ ê°ì§€í•˜ë©´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:

1. ì…ë ¥ì—ì„œ â€˜ìƒˆë¡œìš´ ì •ë³´(new_content)â€™ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.(1. new_content ì •ì œ  
   1.1. ë¬¸ì¥ ë¶€í˜¸(. , â€œ â€ â€˜ â€™ ë“±) ì œê±°  
   1.2. ë¶ˆí•„ìš” ì¡°ì‚¬Â·ì ‘ì†ì‚¬(ëŠ”/ì€/ì´/ê°€, ê·¸ë¦¬ê³ /í•˜ì§€ë§Œ ë“±) ê°„ëµíˆ í•„í„°ë§  
   1.3. íŠ¹ìˆ˜ë¬¸ì(# $ % & * ë“±) íŠ¸ë¦¬ë° )

2. ì•„ë˜ì˜ ê¸°ì¤€ì— ë”°ë¼ â€˜field_nameâ€™ì„ ê²°ì •í•©ë‹ˆë‹¤:
   â€¢ purpose_background  
     â€“ì‚¬ìš©ìê°€ â€˜ì´ìœ â€™, â€˜ëª©ì â€™, â€˜ë°°ê²½â€™ì„ ì–¸ê¸‰í•  ë•Œ  
     â€“ ì˜ˆ: â€œë‚˜ëŠ” ì¼ê¸°ë¥¼ ì“°ë ¤ í•´ìš”â€, â€œì´ í”„ë¡œì íŠ¸ì˜ ëª©ì ì€â€¦â€  
   â€¢ context_topic  
     â€“ ê¸€ì˜ â€˜ì£¼ì œâ€™, â€˜ì´ì•¼ê¸°ê±°ë¦¬â€™, â€˜ì‚¬ë¡€â€™ ë“±ì„ ì§€ì¹­í•  ë•Œ  
     â€“ ì˜ˆ: â€œì£¼ì œëŠ” í™˜ê²½ë³´í˜¸ì…ë‹ˆë‹¤â€, â€œì‚¬ë¡€ë¡œ ì½”ë¡œë‚˜ ì´í›„â€¦â€  
   â€¢ audience_scope  
     â€“ â€˜ëŒ€ìƒâ€™, â€˜ë…ìâ€™, â€˜ëˆ„êµ¬ì—ê²Œâ€™ ê°™ì€ ë‹¨ì–´ê°€ ìˆì„ ë•Œ  
     â€“ ì˜ˆ: â€œë…ìëŠ” í•™ìƒë“¤ì…ë‹ˆë‹¤â€, â€œëŒ€ìƒì€ ì´ˆë³´ê°œë°œìâ€  
   â€¢ format_structure  
     â€“ â€˜í˜•ì‹â€™, â€˜êµ¬ì¡°â€™, â€˜ëª©ì°¨â€™, â€˜íŒŒíŠ¸â€™ ë“±ì„ ì§€ì •í•  ë•Œ  
     â€“ ì˜ˆ: â€œí¬ë§·ì€ ë³´ê³ ì„œ í˜•íƒœë¡œâ€, â€œ1. ì„œë¡ , 2. ë³¸ë¡ â€¦â€  
   â€¢ logic_evidence  
     â€“ â€˜ë…¼ë¦¬ì  íë¦„â€™, â€˜ê·¼ê±°â€™, â€˜ë°ì´í„°â€™, â€˜ì‚¬ë¡€â€™ ë“±ì„ ì–¸ê¸‰ í• ë•Œë•Œ 
     â€“ ì˜ˆ: â€œìš°ë¦¬ê°€ ì „ì— ê²€ìƒ‰í•œ ë‚´ìš© ìˆì–ì•„..â€, â€œì¡°ê¸ˆ ë” ë…¼ë¦¬ì ìœ¼ë¡œ í–ˆìœ¼ë©´ ì¢‹ê² ì–´ì–´â€  
   â€¢ expression_method  
     â€“ â€˜ì–´ì¡°â€™, â€˜ìŠ¤íƒ€ì¼â€™, â€˜í†¤â€™, â€˜ë¬¸ì²´â€™ ì–¸ê¸‰ ì‹œ  
     â€“ ì˜ˆ: â€œì¹œê·¼í•œ ì–´ì¡°ë¡œâ€, â€œê²©ì‹ ìˆëŠ” ë¬¸ì²´ë¡œâ€  
   â€¢ additional_constraints  
     â€“ â€˜ì œí•œâ€™, â€˜ê¸ˆì§€â€™, â€˜ë¶„ëŸ‰â€™, â€˜í‚¤ì›Œë“œâ€™ ê°™ì€ ë¶€ê°€ì¡°ê±´ ì–¸ê¸‰ ì‹œ  
     â€“ ì˜ˆ: â€œ500ì ì´ë‚´ë¡œâ€, â€œâ€˜AIâ€™ë¼ëŠ” ë‹¨ì–´ëŠ” ë¹¼ê³ â€ ,"ì´ë‹¤ ë§ê³  ìŒìŠ´ ì‹ì˜ ê°œì¡°ì²´ë¡œ.."
   â€¢ output_expectations  
     â€“ ìµœì¢… ì‚°ì¶œë¬¼ í˜•íƒœë‚˜ í’ˆì§ˆ ê¸°ì¤€ ì–¸ê¸‰ ì‹œ  
     â€“ ì˜ˆ: â€œìŠ¬ë¼ì´ë“œë¡œ ë§Œë“¤ì–´ì¤˜â€, â€œìš”ì•½ë¬¸ í˜•íƒœë¡œâ€ ,"íšŒì‚¬ì˜ ì–‘ì‹ì„ ì¤„ê²Œ ê·¸ê±°ì— ë”°ë¼ì„œ ì ì–´ì¤˜ì¤˜"

3. ì¶”ì¶œëœ â€˜field_nameâ€™ê³¼ â€˜new_contentâ€™ë¥¼ íŒŒë¼ë¯¸í„°ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤.

ì˜ˆì‹œ:
ì…ë ¥: â€œì²­ì¤‘ì€ ëŒ€í•™ì›ìƒì…ë‹ˆë‹¤.â€
â†’ field_name: â€œaudience_scopeâ€
   new_content: â€œëŒ€í•™ì›ìƒâ€
4.new_contentëŠ” í˜„ì¬ ì¬í™”ë§¥ë½ ì „ì²´ë¥¼ ê³ ë ¤í•´ë¼  (ì˜ˆ) ë§Œì•½ ì´ì „ì— ì‚¬ìš©ìê°€ ê²€ìƒ‰ì„ í•œ ë¬¸ë§¥ì´ ìˆëŠ”ë° ì‚¬ìš©ìê°€ ê·¼ê±°ë¥¼ ì—…ë°ì´íŠ¸í•´ í•˜ë©´ ì´ì „ì— ê²€ìƒ‰í•œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ newcontentë¥¼ ë§Œë“¤ì–´ë¼- ë‹¨ ìµœê·¼ 3ê°œ ëŒ€í™”ë§Œì„ ê³ ë ¤. 
""",
  "strict": True,
  "parameters": {
    "type": "object",
    "required": [
      "field_name",
      "new_content"
    ],
    "properties": {
      "field_name": {
        "type": "string",
        "description": "ì—…ë°ì´íŠ¸í•  í•„ë“œ ì´ë¦„ (writing_requirements ë”•ì…”ë„ˆë¦¬ì˜ í‚¤)",
        "enum": [
          "purpose_background",
          "context_topic",
          "audience_scope",
          "format_structure",
          "logic_evidence",
          "expression_method",
          "additional_constraints",
          "output_expectations"
        ]
      },
      "new_content": {
        "type": "string",
        "description": "í•„ë“œì— ì €ì¥í•  ìƒˆë¡œìš´ ê°’"
      }
    },
    "additionalProperties": False
  }
},
       {
            "type":"function",
            
                "name": "get_writing_requirement_field_content",
                "description": """ì‚¬ìš©ìê°€ ì‘ì„± ìš”êµ¬ ì‚¬í•­ í•„ë“œì˜ ë‚´ìš©ì„ ë³´ê¸¸ ì›í•˜ë©´, ì‚¬ìš©ìê°€ ë³´ê³  ì‹¶ì–´í•˜ëŠ” í•„ë“œë¥¼ í™•ì¸í•˜ì„¸ìš” (í•˜ë‚˜ ë˜ëŠ” ì—¬ëŸ¬ í•„ë“œë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í‘œì‹œí•  í•„ë“œê°€ ì—†ìœ¼ë©´ ëª¨ë“  í•„ë“œë¥¼ í‘œì‹œí•˜ê¸°ë¡œ ê²°ì •í•˜ì„¸ìš”). í˜„ì¬ ì‘ì„±ëœ ì‘ì„± ìš”êµ¬ ì‚¬í•­ í•„ë“œì˜ ë‚´ìš©ì„ ë³´ì—¬ì£¼ì„¸ìš”..""",
                "strict": True,
                "parameters": {
                    "type": "object",
                    "required": [
                    "field_name"
                    ],
                    "properties": {

                    "field_name": {
                        "type": "string",
                        "description": "í™•ì¸í•  íŠ¹ì • í•„ë“œ ì´ë¦„ (ì„ íƒ ì‚¬í•­). ìƒëµí•˜ë©´ ì‘ì„±ëœ ëª¨ë“  í•„ë“œ ë‚´ìš©ì„ ë°˜í™˜í•©ë‹ˆë‹¤.",
                        "enum": [
                        "purpose_background",
                        "context_topic",
                        "audience_scope",
                        "format_structure",
                        "logic_evidence",
                        "expression_method",
                        "additional_constraints",
                        "output_expectations"
                        ]
                    }
                    },
                "additionalProperties": False
                
                }



            }
      
    ]


class FunctionCalling:
    def __init__(self, model):
        self.writingRequirementsManager=WritingRequirementsManager()
        self.available_functions = {
            "get_celsius_temperature": get_celsius_temperature,
            "get_currency": get_currency,
            "search_internet": search_internet,
            "update_field": self.writingRequirementsManager.update_field,
            "get_writing_requirement_field_content": self.writingRequirementsManager.get_field_content,
            "search_internet_for_report": search_internet_for_report,
            "write_report": write_report
        }
        self.model = model
       
    def analyze(self, user_message, tools):
        if not user_message or user_message.strip() == "":
            return {"type": "error", "message": "ì…ë ¥ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."}
    
            # 1. ëª¨ë¸ í˜¸ì¶œ
        response = client.responses.create(
            model=model.o3_mini,
            input=user_message,
            tools=tools,
            tool_choice="auto",
            
        )
        return response.output
    

    def run(self, analyzed,context):
 
        context.append(analyzed)
        for tool_call in analyzed:
            if tool_call.get("type") != "function_call":
                continue
            function=tool_call["function"]
            func_name=function["name"]
            #ì‹¤ì œ í•¨ìˆ˜ì™€ ì—°ê²°
            func_to_call = self.available_functions[func_name]

            try:

                func_args=json.loads(function["arguments"])#ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜-> ë¬¸ìì—´ì´ jsoní˜•íƒœì…-> ì´ê±¸ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                
                if func_name == "search_internet":
                    # contextëŠ” ì´ë¯¸ run ë©”ì„œë“œì˜ ë§¤ê°œë³€ìˆ˜ë¡œ ë°›ê³  ìˆìŒ
                    func_response = func_to_call(chat_context=context[:], **func_args)
                else:
                    func_response=func_to_call(**func_args)
                context.append({
                    "tool_call_id": tool_call["id"],
                    "role": "tool",
                    "name": func_name, 
                    "content": str(func_response),
                    "parallel_tool_calls": True
                })#ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¬¸ë§¥ì— ì¶”ê°€
  

            except Exception as e:
                print("Error occurred(run):",e)
                return makeup_response("[run ì˜¤ë¥˜ì…ë‹ˆë‹¤]")
        return client.responses.create(model=self.model,input=context).model_dump()
    
    def run_report(self, analyzed_dict, context):
        func_name = analyzed_dict["function_call"]["name"]
        func_to_call = self.available_functions[func_name]        
        try:
            func_args = json.loads(analyzed_dict["function_call"]["arguments"])
            # ì±—GPTê°€ ì•Œë ¤ì£¼ëŠ” ë§¤ê°œë³€ìˆ˜ëª…ê³¼ ê°’ì„ ì…ë ¥ê°’ìœ¼ë¡œí•˜ì—¬ ì‹¤ì œ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•œë‹¤.
            func_response = func_to_call(**func_args)
            context.append({
                "role": "function", 
                "name": func_name, 
                "content": str(func_response)
            })
            return client.chat.completions.create(model=self.model,messages=context).model_dump()            
        except Exception as e:
            print("Error occurred(run):",e)
            return makeup_response("[run ì˜¤ë¥˜ì…ë‹ˆë‹¤]")

    def call_function(self, analyzed_dict):        
        func_name = analyzed_dict["function_call"]["name"]
        func_to_call = self.available_functions[func_name]                
        try:            
            func_args = json.loads(analyzed_dict["function_call"]["arguments"])
            func_response = func_to_call(**func_args)
            return str(func_response)
        except Exception as e:
            print("Error occurred(call_function):",e)
            return makeup_response("[call_function ì˜¤ë¥˜ì…ë‹ˆë‹¤]")
    